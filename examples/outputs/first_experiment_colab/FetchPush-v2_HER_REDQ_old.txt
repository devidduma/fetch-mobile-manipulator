2023-02-28 19:33:45.080589: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.8/dist-packages/mujoco_py/binaries/linux/mujoco210/bin
2023-02-28 19:33:45.080701: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.8/dist-packages/mujoco_py/binaries/linux/mujoco210/bin
2023-02-28 19:33:45.080721: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
Observations shape: {'observation': (25,), 'achieved_goal': (3,), 'desired_goal': (3,)}
Actions shape: (4,)
Action range: -1.0 1.0
Epoch #1: 5001it [03:24, 24.40it/s, env_step=5000, len=50, loss/actor=-6.442, loss/critics=0.954, n/ep=1, n/st=1, rew=-50.00]
Epoch #1: test_reward: -50.000000 ± 0.000000, best_reward: -45.000000 ± 15.000000 in #0
Epoch #2: 5001it [03:25, 24.29it/s, env_step=10000, len=50, loss/actor=-8.966, loss/critics=2.160, n/ep=1, n/st=1, rew=-50.00]
Epoch #2: test_reward: -45.000000 ± 15.000000, best_reward: -45.000000 ± 15.000000 in #0
Epoch #3: 5001it [03:36, 23.08it/s, env_step=15000, len=50, loss/actor=-10.321, loss/critics=3.406, n/ep=1, n/st=1, rew=-50.00]
Epoch #3: test_reward: -50.000000 ± 0.000000, best_reward: -45.000000 ± 15.000000 in #0
Epoch #4: 5001it [03:44, 22.30it/s, env_step=20000, len=50, loss/actor=-11.472, loss/critics=3.975, n/ep=1, n/st=1, rew=-50.00]
Epoch #4: test_reward: -50.000000 ± 0.000000, best_reward: -45.000000 ± 15.000000 in #0
Epoch #5: 5001it [03:47, 21.98it/s, env_step=25000, len=50, loss/actor=-12.505, loss/critics=5.102, n/ep=1, n/st=1, rew=-50.00]
Epoch #5: test_reward: -50.000000 ± 0.000000, best_reward: -45.000000 ± 15.000000 in #0
Epoch #6: 5001it [03:52, 21.55it/s, env_step=30000, len=50, loss/actor=-13.466, loss/critics=5.468, n/ep=1, n/st=1, rew=-50.00]
Epoch #6: test_reward: -45.000000 ± 15.000000, best_reward: -45.000000 ± 15.000000 in #0
Epoch #7: 5001it [03:55, 21.25it/s, env_step=35000, len=50, loss/actor=-14.407, loss/critics=6.032, n/ep=1, n/st=1, rew=-50.00]
Epoch #7: test_reward: -50.000000 ± 0.000000, best_reward: -45.000000 ± 15.000000 in #0
Epoch #8: 5001it [04:01, 20.67it/s, env_step=40000, len=50, loss/actor=-15.225, loss/critics=6.402, n/ep=1, n/st=1, rew=-50.00]
Epoch #8: test_reward: -50.000000 ± 0.000000, best_reward: -45.000000 ± 15.000000 in #0
Epoch #9: 5001it [04:13, 19.77it/s, env_step=45000, len=50, loss/actor=-16.002, loss/critics=6.616, n/ep=1, n/st=1, rew=-50.00]
Epoch #9: test_reward: -50.000000 ± 0.000000, best_reward: -45.000000 ± 15.000000 in #0
Epoch #10: 5001it [04:13, 19.69it/s, env_step=50000, len=50, loss/actor=-16.616, loss/critics=7.093, n/ep=1, n/st=1, rew=-50.00]
Epoch #10: test_reward: -45.000000 ± 15.000000, best_reward: -45.000000 ± 15.000000 in #0
Epoch #11: 5001it [04:18, 19.35it/s, env_step=55000, len=50, loss/actor=-16.976, loss/critics=7.485, n/ep=1, n/st=1, rew=-50.00]
Epoch #11: test_reward: -50.000000 ± 0.000000, best_reward: -45.000000 ± 15.000000 in #0
Epoch #12: 5001it [04:18, 19.33it/s, env_step=60000, len=50, loss/actor=-17.236, loss/critics=7.520, n/ep=1, n/st=1, rew=-50.00]
Epoch #12: test_reward: -50.000000 ± 0.000000, best_reward: -45.000000 ± 15.000000 in #0
Epoch #13: 5001it [04:21, 19.10it/s, env_step=65000, len=50, loss/actor=-17.173, loss/critics=7.649, n/ep=1, n/st=1, rew=-50.00]
Epoch #13: test_reward: -40.000000 ± 20.000000, best_reward: -40.000000 ± 20.000000 in #13
Epoch #14: 5001it [04:23, 18.98it/s, env_step=70000, len=50, loss/actor=-16.794, loss/critics=6.609, n/ep=1, n/st=1, rew=-50.00]
Epoch #14: test_reward: -45.000000 ± 15.000000, best_reward: -40.000000 ± 20.000000 in #13
Epoch #15: 5001it [04:25, 18.81it/s, env_step=75000, len=50, loss/actor=-16.356, loss/critics=6.610, n/ep=1, n/st=1, rew=0.00]
Epoch #15: test_reward: -50.000000 ± 0.000000, best_reward: -40.000000 ± 20.000000 in #13
Epoch #16: 5001it [04:25, 18.86it/s, env_step=80000, len=50, loss/actor=-16.130, loss/critics=5.965, n/ep=1, n/st=1, rew=-50.00]
Epoch #16: test_reward: -40.000000 ± 20.000000, best_reward: -40.000000 ± 20.000000 in #13
Epoch #17: 5001it [04:28, 18.66it/s, env_step=85000, len=50, loss/actor=-15.539, loss/critics=5.815, n/ep=1, n/st=1, rew=-50.00]
Epoch #17: test_reward: -45.000000 ± 15.000000, best_reward: -40.000000 ± 20.000000 in #13
Epoch #18: 5001it [04:26, 18.73it/s, env_step=90000, len=50, loss/actor=-15.059, loss/critics=5.284, n/ep=1, n/st=1, rew=-50.00]
Epoch #18: test_reward: -50.000000 ± 0.000000, best_reward: -40.000000 ± 20.000000 in #13
Epoch #19: 5001it [04:27, 18.70it/s, env_step=95000, len=50, loss/actor=-14.401, loss/critics=4.662, n/ep=1, n/st=1, rew=-50.00]
Epoch #19: test_reward: -50.000000 ± 0.000000, best_reward: -40.000000 ± 20.000000 in #13
Epoch #20: 5001it [04:25, 18.81it/s, env_step=100000, len=50, loss/actor=-13.808, loss/critics=4.279, n/ep=1, n/st=1, rew=-50.00]
Epoch #20: test_reward: -50.000000 ± 0.000000, best_reward: -40.000000 ± 20.000000 in #13
Epoch #21: 5001it [04:26, 18.80it/s, env_step=105000, len=50, loss/actor=-13.530, loss/critics=3.741, n/ep=1, n/st=1, rew=-50.00]
Epoch #21: test_reward: -45.000000 ± 15.000000, best_reward: -40.000000 ± 20.000000 in #13
Epoch #22: 5001it [04:24, 18.94it/s, env_step=110000, len=50, loss/actor=-13.115, loss/critics=3.448, n/ep=1, n/st=1, rew=-50.00]
Epoch #22: test_reward: -45.000000 ± 15.000000, best_reward: -40.000000 ± 20.000000 in #13
Epoch #23: 5001it [04:22, 19.02it/s, env_step=115000, len=50, loss/actor=-13.011, loss/critics=3.244, n/ep=1, n/st=1, rew=-50.00]
Epoch #23: test_reward: -45.000000 ± 15.000000, best_reward: -40.000000 ± 20.000000 in #13
Epoch #24: 5001it [04:24, 18.94it/s, env_step=120000, len=50, loss/actor=-12.644, loss/critics=2.713, n/ep=1, n/st=1, rew=-50.00]
Epoch #24: test_reward: -50.000000 ± 0.000000, best_reward: -40.000000 ± 20.000000 in #13
Epoch #25: 5001it [04:23, 19.00it/s, env_step=125000, len=50, loss/actor=-12.528, loss/critics=2.635, n/ep=1, n/st=1, rew=-50.00]
Epoch #25: test_reward: -45.000000 ± 15.000000, best_reward: -40.000000 ± 20.000000 in #13
Epoch #26: 5001it [04:25, 18.85it/s, env_step=130000, len=50, loss/actor=-12.519, loss/critics=2.434, n/ep=1, n/st=1, rew=-50.00]
Epoch #26: test_reward: -50.000000 ± 0.000000, best_reward: -40.000000 ± 20.000000 in #13
Epoch #27: 5001it [04:25, 18.80it/s, env_step=135000, len=50, loss/actor=-12.430, loss/critics=2.409, n/ep=1, n/st=1, rew=-50.00]
Epoch #27: test_reward: -45.000000 ± 15.000000, best_reward: -40.000000 ± 20.000000 in #13
Epoch #28: 5001it [04:25, 18.83it/s, env_step=140000, len=50, loss/actor=-12.538, loss/critics=2.301, n/ep=1, n/st=1, rew=-50.00]
Epoch #28: test_reward: -50.000000 ± 0.000000, best_reward: -40.000000 ± 20.000000 in #13
Epoch #29: 5001it [04:24, 18.89it/s, env_step=145000, len=50, loss/actor=-12.633, loss/critics=2.289, n/ep=1, n/st=1, rew=-50.00]
Epoch #29: test_reward: -50.000000 ± 0.000000, best_reward: -40.000000 ± 20.000000 in #13
Epoch #30: 5001it [04:24, 18.88it/s, env_step=150000, len=50, loss/actor=-12.806, loss/critics=2.244, n/ep=1, n/st=1, rew=-50.00]
Epoch #30: test_reward: -45.000000 ± 15.000000, best_reward: -40.000000 ± 20.000000 in #13
Epoch #31: 5001it [04:26, 18.74it/s, env_step=155000, len=50, loss/actor=-12.770, loss/critics=2.147, n/ep=1, n/st=1, rew=-50.00]
Epoch #31: test_reward: -50.000000 ± 0.000000, best_reward: -40.000000 ± 20.000000 in #13
Epoch #32: 5001it [04:25, 18.81it/s, env_step=160000, len=50, loss/actor=-12.721, loss/critics=2.166, n/ep=1, n/st=1, rew=-50.00]
Epoch #32: test_reward: -45.000000 ± 15.000000, best_reward: -40.000000 ± 20.000000 in #13
Epoch #33: 5001it [04:26, 18.79it/s, env_step=165000, len=50, loss/actor=-12.893, loss/critics=2.117, n/ep=1, n/st=1, rew=-50.00]
Epoch #33: test_reward: -45.000000 ± 15.000000, best_reward: -40.000000 ± 20.000000 in #13
Epoch #34: 5001it [04:26, 18.77it/s, env_step=170000, len=50, loss/actor=-12.801, loss/critics=2.090, n/ep=1, n/st=1, rew=-50.00]
Epoch #34: test_reward: -50.000000 ± 0.000000, best_reward: -40.000000 ± 20.000000 in #13
Epoch #35: 5001it [04:27, 18.72it/s, env_step=175000, len=50, loss/actor=-12.749, loss/critics=2.042, n/ep=1, n/st=1, rew=-50.00]
Epoch #35: test_reward: -50.000000 ± 0.000000, best_reward: -40.000000 ± 20.000000 in #13
Epoch #36: 5001it [04:27, 18.72it/s, env_step=180000, len=50, loss/actor=-12.689, loss/critics=1.900, n/ep=1, n/st=1, rew=-50.00]
Epoch #36: test_reward: -45.000000 ± 15.000000, best_reward: -40.000000 ± 20.000000 in #13
Epoch #37: 5001it [04:26, 18.79it/s, env_step=185000, len=50, loss/actor=-12.627, loss/critics=2.004, n/ep=1, n/st=1, rew=0.00]
Epoch #37: test_reward: -45.000000 ± 15.000000, best_reward: -40.000000 ± 20.000000 in #13
Epoch #38: 5001it [04:26, 18.75it/s, env_step=190000, len=50, loss/actor=-12.536, loss/critics=1.804, n/ep=1, n/st=1, rew=-50.00]
Epoch #38: test_reward: -40.000000 ± 20.000000, best_reward: -40.000000 ± 20.000000 in #13
Epoch #39: 5001it [04:25, 18.80it/s, env_step=195000, len=50, loss/actor=-12.509, loss/critics=1.861, n/ep=1, n/st=1, rew=-50.00]
Epoch #39: test_reward: -45.000000 ± 15.000000, best_reward: -40.000000 ± 20.000000 in #13
Epoch #40: 5001it [04:25, 18.81it/s, env_step=200000, len=50, loss/actor=-12.428, loss/critics=1.793, n/ep=1, n/st=1, rew=0.00]
Epoch #40: test_reward: -42.000000 ± 16.613248, best_reward: -40.000000 ± 20.000000 in #13
Epoch #41: 5001it [04:24, 18.88it/s, env_step=205000, len=50, loss/actor=-12.294, loss/critics=1.962, n/ep=1, n/st=1, rew=-50.00]
Epoch #41: test_reward: -50.000000 ± 0.000000, best_reward: -40.000000 ± 20.000000 in #13
Epoch #42: 5001it [04:25, 18.81it/s, env_step=210000, len=50, loss/actor=-12.089, loss/critics=1.935, n/ep=1, n/st=1, rew=-50.00]
Epoch #42: test_reward: -50.000000 ± 0.000000, best_reward: -40.000000 ± 20.000000 in #13
Epoch #43: 5001it [04:25, 18.84it/s, env_step=215000, len=50, loss/actor=-12.102, loss/critics=1.762, n/ep=1, n/st=1, rew=-50.00]
Epoch #43: test_reward: -50.000000 ± 0.000000, best_reward: -40.000000 ± 20.000000 in #13
Epoch #44: 5001it [04:25, 18.83it/s, env_step=220000, len=50, loss/actor=-11.976, loss/critics=1.914, n/ep=1, n/st=1, rew=-50.00]
Epoch #44: test_reward: -45.000000 ± 15.000000, best_reward: -40.000000 ± 20.000000 in #13
Epoch #45: 5001it [04:25, 18.81it/s, env_step=225000, len=50, loss/actor=-11.887, loss/critics=2.027, n/ep=1, n/st=1, rew=-50.00]
Epoch #45: test_reward: -45.000000 ± 15.000000, best_reward: -40.000000 ± 20.000000 in #13
Epoch #46: 5001it [04:25, 18.81it/s, env_step=230000, len=50, loss/actor=-11.825, loss/critics=1.953, n/ep=1, n/st=1, rew=-50.00]
Epoch #46: test_reward: -45.000000 ± 15.000000, best_reward: -40.000000 ± 20.000000 in #13
Epoch #47: 5001it [04:25, 18.86it/s, env_step=235000, len=50, loss/actor=-11.785, loss/critics=1.992, n/ep=1, n/st=1, rew=-50.00]
Epoch #47: test_reward: -50.000000 ± 0.000000, best_reward: -40.000000 ± 20.000000 in #13
Epoch #48: 5001it [04:25, 18.81it/s, env_step=240000, len=50, loss/actor=-11.913, loss/critics=1.994, n/ep=1, n/st=1, rew=-50.00]
Epoch #48: test_reward: -50.000000 ± 0.000000, best_reward: -40.000000 ± 20.000000 in #13
Epoch #49: 5001it [04:25, 18.83it/s, env_step=245000, len=50, loss/actor=-11.772, loss/critics=1.941, n/ep=1, n/st=1, rew=-50.00]
Epoch #49: test_reward: -50.000000 ± 0.000000, best_reward: -40.000000 ± 20.000000 in #13
Epoch #50: 5001it [04:26, 18.76it/s, env_step=250000, len=50, loss/actor=-11.895, loss/critics=1.938, n/ep=1, n/st=1, rew=-50.00]
Epoch #50: test_reward: -40.000000 ± 20.000000, best_reward: -40.000000 ± 20.000000 in #13
Epoch #51: 5001it [04:26, 18.78it/s, env_step=255000, len=50, loss/actor=-11.812, loss/critics=1.982, n/ep=1, n/st=1, rew=-24.00]
Epoch #51: test_reward: -45.000000 ± 15.000000, best_reward: -40.000000 ± 20.000000 in #13
Epoch #52: 5001it [04:27, 18.68it/s, env_step=260000, len=50, loss/actor=-11.846, loss/critics=2.046, n/ep=1, n/st=1, rew=0.00]
Epoch #52: test_reward: -49.200000 ± 2.400000, best_reward: -40.000000 ± 20.000000 in #13
Epoch #53: 5001it [04:27, 18.71it/s, env_step=265000, len=50, loss/actor=-11.731, loss/critics=1.959, n/ep=1, n/st=1, rew=0.00]
Epoch #53: test_reward: -35.400000 ± 22.325770, best_reward: -35.400000 ± 22.325770 in #53
Epoch #54: 5001it [04:26, 18.78it/s, env_step=270000, len=50, loss/actor=-11.842, loss/critics=2.278, n/ep=1, n/st=1, rew=-50.00]
Epoch #54: test_reward: -45.000000 ± 15.000000, best_reward: -35.400000 ± 22.325770 in #53
Epoch #55: 5001it [04:26, 18.75it/s, env_step=275000, len=50, loss/actor=-11.661, loss/critics=2.060, n/ep=1, n/st=1, rew=-50.00]
Epoch #55: test_reward: -45.000000 ± 15.000000, best_reward: -35.400000 ± 22.325770 in #53
Epoch #56: 5001it [04:26, 18.77it/s, env_step=280000, len=50, loss/actor=-11.577, loss/critics=2.023, n/ep=1, n/st=1, rew=-50.00]
Epoch #56: test_reward: -45.000000 ± 15.000000, best_reward: -35.400000 ± 22.325770 in #53
Epoch #57: 5001it [04:26, 18.75it/s, env_step=285000, len=50, loss/actor=-11.488, loss/critics=1.897, n/ep=1, n/st=1, rew=-50.00]
Epoch #57: test_reward: -45.000000 ± 15.000000, best_reward: -35.400000 ± 22.325770 in #53
Epoch #58: 5001it [04:26, 18.74it/s, env_step=290000, len=50, loss/actor=-11.346, loss/critics=1.918, n/ep=1, n/st=1, rew=-50.00]
Epoch #58: test_reward: -45.000000 ± 15.000000, best_reward: -35.400000 ± 22.325770 in #53
Epoch #59: 5001it [04:26, 18.73it/s, env_step=295000, len=50, loss/actor=-11.319, loss/critics=2.183, n/ep=1, n/st=1, rew=-50.00]
Epoch #59: test_reward: -50.000000 ± 0.000000, best_reward: -35.400000 ± 22.325770 in #53
Epoch #60: 5001it [04:25, 18.82it/s, env_step=300000, len=50, loss/actor=-11.243, loss/critics=2.040, n/ep=1, n/st=1, rew=-50.00]
Epoch #60: test_reward: -45.000000 ± 15.000000, best_reward: -35.400000 ± 22.325770 in #53
Epoch #61: 5001it [04:22, 19.05it/s, env_step=305000, len=50, loss/actor=-11.254, loss/critics=2.033, n/ep=1, n/st=1, rew=-50.00]
Epoch #61: test_reward: -45.000000 ± 15.000000, best_reward: -35.400000 ± 22.325770 in #53
Epoch #62: 5001it [04:21, 19.09it/s, env_step=310000, len=50, loss/actor=-11.010, loss/critics=1.939, n/ep=1, n/st=1, rew=-50.00]
Epoch #62: test_reward: -50.000000 ± 0.000000, best_reward: -35.400000 ± 22.325770 in #53
Epoch #63: 5001it [04:22, 19.04it/s, env_step=315000, len=50, loss/actor=-10.888, loss/critics=2.042, n/ep=1, n/st=1, rew=0.00]
Epoch #63: test_reward: -40.000000 ± 20.000000, best_reward: -35.400000 ± 22.325770 in #53
Epoch #64: 5001it [04:22, 19.07it/s, env_step=320000, len=50, loss/actor=-10.757, loss/critics=2.062, n/ep=1, n/st=1, rew=-50.00]
Epoch #64: test_reward: -40.000000 ± 20.000000, best_reward: -35.400000 ± 22.325770 in #53
Epoch #65: 5001it [04:21, 19.13it/s, env_step=325000, len=50, loss/actor=-10.887, loss/critics=1.947, n/ep=1, n/st=1, rew=-50.00]
Epoch #65: test_reward: -50.000000 ± 0.000000, best_reward: -35.400000 ± 22.325770 in #53
Epoch #66: 5001it [04:20, 19.18it/s, env_step=330000, len=50, loss/actor=-10.744, loss/critics=1.963, n/ep=1, n/st=1, rew=-50.00]
Epoch #66: test_reward: -50.000000 ± 0.000000, best_reward: -35.400000 ± 22.325770 in #53
Epoch #67: 5001it [04:20, 19.18it/s, env_step=335000, len=50, loss/actor=-10.605, loss/critics=1.898, n/ep=1, n/st=1, rew=-50.00]
Epoch #67: test_reward: -50.000000 ± 0.000000, best_reward: -35.400000 ± 22.325770 in #53
Epoch #68: 5001it [04:25, 18.83it/s, env_step=340000, len=50, loss/actor=-10.544, loss/critics=1.816, n/ep=1, n/st=1, rew=-50.00]
Epoch #68: test_reward: -50.000000 ± 0.000000, best_reward: -35.400000 ± 22.325770 in #53
Epoch #69: 5001it [04:31, 18.42it/s, env_step=345000, len=50, loss/actor=-10.667, loss/critics=1.807, n/ep=1, n/st=1, rew=-50.00]
Epoch #69: test_reward: -45.000000 ± 15.000000, best_reward: -35.400000 ± 22.325770 in #53
Epoch #70: 5001it [04:24, 18.89it/s, env_step=350000, len=50, loss/actor=-10.685, loss/critics=1.946, n/ep=1, n/st=1, rew=-50.00]
Epoch #70: test_reward: -50.000000 ± 0.000000, best_reward: -35.400000 ± 22.325770 in #53
Epoch #71: 5001it [04:47, 17.38it/s, env_step=355000, len=50, loss/actor=-10.532, loss/critics=2.004, n/ep=1, n/st=1, rew=-50.00]
Epoch #71: test_reward: -50.000000 ± 0.000000, best_reward: -35.400000 ± 22.325770 in #53
Epoch #72: 5001it [04:12, 19.84it/s, env_step=360000, len=50, loss/actor=-10.535, loss/critics=2.064, n/ep=1, n/st=1, rew=-50.00]
Epoch #72: test_reward: -50.000000 ± 0.000000, best_reward: -35.400000 ± 22.325770 in #53
Epoch #73: 5001it [04:12, 19.82it/s, env_step=365000, len=50, loss/actor=-10.495, loss/critics=1.917, n/ep=1, n/st=1, rew=-50.00]
Epoch #73: test_reward: -45.000000 ± 15.000000, best_reward: -35.400000 ± 22.325770 in #53
Epoch #74: 5001it [04:10, 19.97it/s, env_step=370000, len=50, loss/actor=-10.623, loss/critics=2.107, n/ep=1, n/st=1, rew=-50.00]
Epoch #74: test_reward: -40.000000 ± 20.000000, best_reward: -35.400000 ± 22.325770 in #53
Epoch #75: 5001it [04:10, 19.99it/s, env_step=375000, len=50, loss/actor=-10.783, loss/critics=2.181, n/ep=1, n/st=1, rew=-50.00]
Epoch #75: test_reward: -50.000000 ± 0.000000, best_reward: -35.400000 ± 22.325770 in #53
Epoch #76: 5001it [04:14, 19.63it/s, env_step=380000, len=50, loss/actor=-10.819, loss/critics=2.345, n/ep=1, n/st=1, rew=-50.00]
Epoch #76: test_reward: -40.700000 ± 17.435883, best_reward: -35.400000 ± 22.325770 in #53
Epoch #77: 5001it [04:12, 19.84it/s, env_step=385000, len=50, loss/actor=-10.661, loss/critics=2.300, n/ep=1, n/st=1, rew=-50.00]
Epoch #77: test_reward: -36.100000 ± 21.421718, best_reward: -35.400000 ± 22.325770 in #53
Epoch #78: 5001it [04:14, 19.69it/s, env_step=390000, len=50, loss/actor=-10.450, loss/critics=2.225, n/ep=1, n/st=1, rew=-50.00]
Epoch #78: test_reward: -37.600000 ± 19.617339, best_reward: -35.400000 ± 22.325770 in #53
Epoch #79: 5001it [04:11, 19.87it/s, env_step=395000, len=50, loss/actor=-10.261, loss/critics=2.410, n/ep=1, n/st=1, rew=-50.00]
Epoch #79: test_reward: -50.000000 ± 0.000000, best_reward: -35.400000 ± 22.325770 in #53
Epoch #80: 5001it [04:23, 18.97it/s, env_step=400000, len=50, loss/actor=-10.060, loss/critics=2.311, n/ep=1, n/st=1, rew=-50.00]
Epoch #80: test_reward: -50.000000 ± 0.000000, best_reward: -35.400000 ± 22.325770 in #53
Epoch #81: 5001it [04:10, 20.00it/s, env_step=405000, len=50, loss/actor=-9.817, loss/critics=2.426, n/ep=1, n/st=1, rew=-50.00]
Epoch #81: test_reward: -44.300000 ± 14.913417, best_reward: -35.400000 ± 22.325770 in #53
Epoch #82: 5001it [04:09, 20.08it/s, env_step=410000, len=50, loss/actor=-9.661, loss/critics=2.576, n/ep=1, n/st=1, rew=-50.00]
Epoch #82: test_reward: -50.000000 ± 0.000000, best_reward: -35.400000 ± 22.325770 in #53
Epoch #83: 5001it [04:08, 20.15it/s, env_step=415000, len=50, loss/actor=-9.478, loss/critics=2.464, n/ep=1, n/st=1, rew=-50.00]
Epoch #83: test_reward: -49.800000 ± 0.600000, best_reward: -35.400000 ± 22.325770 in #53
Epoch #84: 5001it [04:14, 19.62it/s, env_step=420000, len=50, loss/actor=-9.184, loss/critics=2.529, n/ep=1, n/st=1, rew=-25.00]
Epoch #84: test_reward: -50.000000 ± 0.000000, best_reward: -35.400000 ± 22.325770 in #53
Epoch #85: 5001it [04:26, 18.74it/s, env_step=425000, len=50, loss/actor=-8.872, loss/critics=2.560, n/ep=1, n/st=1, rew=-50.00]
Epoch #85: test_reward: -45.000000 ± 15.000000, best_reward: -35.400000 ± 22.325770 in #53
Epoch #86: 5001it [04:17, 19.38it/s, env_step=430000, len=50, loss/actor=-8.661, loss/critics=2.499, n/ep=1, n/st=1, rew=-50.00]
Epoch #86: test_reward: -50.000000 ± 0.000000, best_reward: -35.400000 ± 22.325770 in #53
Epoch #87: 5001it [04:28, 18.64it/s, env_step=435000, len=50, loss/actor=-8.401, loss/critics=2.507, n/ep=1, n/st=1, rew=-50.00]
Epoch #87: test_reward: -37.400000 ± 19.622436, best_reward: -35.400000 ± 22.325770 in #53
Epoch #88: 5001it [04:25, 18.83it/s, env_step=440000, len=50, loss/actor=-7.943, loss/critics=2.422, n/ep=1, n/st=1, rew=-39.00]
Epoch #88: test_reward: -41.100000 ± 17.969140, best_reward: -35.400000 ± 22.325770 in #53
Epoch #89: 5001it [04:24, 18.89it/s, env_step=445000, len=50, loss/actor=-7.718, loss/critics=2.404, n/ep=1, n/st=1, rew=-50.00]
Epoch #89: test_reward: -44.400000 ± 11.629273, best_reward: -35.400000 ± 22.325770 in #53
Epoch #90: 5001it [04:23, 18.96it/s, env_step=450000, len=50, loss/actor=-7.363, loss/critics=2.277, n/ep=1, n/st=1, rew=-50.00]
Epoch #90: test_reward: -39.400000 ± 16.044937, best_reward: -35.400000 ± 22.325770 in #53
Epoch #91: 5001it [04:22, 19.03it/s, env_step=455000, len=50, loss/actor=-7.054, loss/critics=2.437, n/ep=1, n/st=1, rew=-50.00]
Epoch #91: test_reward: -38.300000 ± 17.877640, best_reward: -35.400000 ± 22.325770 in #53
Epoch #92: 5001it [04:21, 19.14it/s, env_step=460000, len=50, loss/actor=-6.800, loss/critics=2.528, n/ep=1, n/st=1, rew=-50.00]
Epoch #92: test_reward: -41.200000 ± 15.190787, best_reward: -35.400000 ± 22.325770 in #53
Epoch #93: 5001it [04:15, 19.60it/s, env_step=465000, len=50, loss/actor=-6.586, loss/critics=2.515, n/ep=1, n/st=1, rew=-50.00]
Epoch #93: test_reward: -31.100000 ± 19.511279, best_reward: -31.100000 ± 19.511279 in #93
Epoch #94: 5001it [04:20, 19.18it/s, env_step=470000, len=50, loss/actor=-6.332, loss/critics=2.508, n/ep=1, n/st=1, rew=-50.00]
Epoch #94: test_reward: -22.700000 ± 18.028034, best_reward: -22.700000 ± 18.028034 in #94
Epoch #95: 5001it [04:19, 19.29it/s, env_step=475000, len=50, loss/actor=-6.194, loss/critics=2.654, n/ep=1, n/st=1, rew=-50.00]
Epoch #95: test_reward: -40.600000 ± 17.596591, best_reward: -22.700000 ± 18.028034 in #94
Epoch #96: 5001it [04:18, 19.36it/s, env_step=480000, len=50, loss/actor=-6.063, loss/critics=2.678, n/ep=1, n/st=1, rew=-23.00]
Epoch #96: test_reward: -37.500000 ± 16.390546, best_reward: -22.700000 ± 18.028034 in #94
Epoch #97: 5001it [04:21, 19.11it/s, env_step=485000, len=50, loss/actor=-5.853, loss/critics=2.670, n/ep=1, n/st=1, rew=-13.00]
Epoch #97: test_reward: -30.900000 ± 21.833232, best_reward: -22.700000 ± 18.028034 in #94
Epoch #98: 5001it [04:19, 19.25it/s, env_step=490000, len=50, loss/actor=-5.635, loss/critics=2.689, n/ep=1, n/st=1, rew=-50.00]
Epoch #98: test_reward: -20.600000 ± 19.805050, best_reward: -20.600000 ± 19.805050 in #98
Epoch #99: 5001it [04:18, 19.36it/s, env_step=495000, len=50, loss/actor=-5.434, loss/critics=2.694, n/ep=1, n/st=1, rew=-38.00]
Epoch #99: test_reward: -25.700000 ± 17.430146, best_reward: -20.600000 ± 19.805050 in #98
Epoch #100: 5001it [04:15, 19.54it/s, env_step=500000, len=50, loss/actor=-5.415, loss/critics=2.551, n/ep=1, n/st=1, rew=-29.00]
Epoch #100: test_reward: -19.200000 ± 13.444702, best_reward: -19.200000 ± 13.444702 in #100
{'best_result': '-19.20 ± 13.44',
 'best_reward': -19.2,
 'duration': '26002.10s',
 'test_episode': 1010,
 'test_speed': '1156.74 step/s',
 'test_step': 50500,
 'test_time': '43.66s',
 'train_episode': 10000,
 'train_speed': '19.26 step/s',
 'train_step': 500000,
 'train_time/collector': '5211.67s',
 'train_time/model': '20746.78s'}
Final reward: -19.3, length: 50.0
