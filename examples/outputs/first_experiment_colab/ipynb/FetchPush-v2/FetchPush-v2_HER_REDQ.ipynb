{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IO0ADjYzh7T1",
    "outputId": "5d69920d-2f13-452c-dd6a-95f058995e98"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[31mERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'\u001B[0m\u001B[31m\n",
      "\u001B[0m"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wfuzeq7BitX9",
    "outputId": "11bfa042-a3d2-44c5-c0a2-1b3b052b9da0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Preparing metadata (setup.py) ... \u001B[?25l\u001B[?25hdone\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/Markus28/tianshou.git@gymnasium_integration#egg=tianshou --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UyOq9We-I6ay",
    "outputId": "2e0f4c58-4164-4279-c047-17ef480ad658"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists...\n",
      "Building dependency tree...\n",
      "Reading state information...\n",
      "libglew-dev is already the newest version (2.1.0-4).\n",
      "libgl1-mesa-dev is already the newest version (21.2.6-0ubuntu0.1~20.04.2).\n",
      "libgl1-mesa-glx is already the newest version (21.2.6-0ubuntu0.1~20.04.2).\n",
      "libosmesa6-dev is already the newest version (21.2.6-0ubuntu0.1~20.04.2).\n",
      "software-properties-common is already the newest version (0.99.9.10).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 19 not upgraded.\n",
      "Reading package lists...\n",
      "Building dependency tree...\n",
      "Reading state information...\n",
      "patchelf is already the newest version (0.10-2build1).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 19 not upgraded.\n"
     ]
    }
   ],
   "source": [
    "!apt-get -q install -y \\\n",
    "    libgl1-mesa-dev \\\n",
    "    libgl1-mesa-glx \\\n",
    "    libglew-dev \\\n",
    "    libosmesa6-dev \\\n",
    "    software-properties-common\n",
    "\n",
    "!apt-get -q install -y patchelf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UbOlVWv0157i"
   },
   "outputs": [],
   "source": [
    "!pip install envpool wandb pettingzoo gymnasium-robotics --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fCkkosakI_bC"
   },
   "outputs": [],
   "source": [
    "!pip install free-mujoco-py --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7TZHDrP1JTUj"
   },
   "outputs": [],
   "source": [
    "import mujoco_py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jtbz6g5yj3FL",
    "outputId": "2842bde2-7bf0-4e6a-9192-9945a4f337e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-02-28 19:33:45.080589: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.8/dist-packages/mujoco_py/binaries/linux/mujoco210/bin\n",
      "2023-02-28 19:33:45.080701: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.8/dist-packages/mujoco_py/binaries/linux/mujoco210/bin\n",
      "2023-02-28 19:33:45.080721: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Observations shape: {'observation': (25,), 'achieved_goal': (3,), 'desired_goal': (3,)}\n",
      "Actions shape: (4,)\n",
      "Action range: -1.0 1.0\n",
      "Epoch #1: 5001it [03:24, 24.40it/s, env_step=5000, len=50, loss/actor=-6.442, loss/critics=0.954, n/ep=1, n/st=1, rew=-50.00]              \n",
      "Epoch #1: test_reward: -50.000000 ± 0.000000, best_reward: -45.000000 ± 15.000000 in #0\n",
      "Epoch #2: 5001it [03:25, 24.29it/s, env_step=10000, len=50, loss/actor=-8.966, loss/critics=2.160, n/ep=1, n/st=1, rew=-50.00]              \n",
      "Epoch #2: test_reward: -45.000000 ± 15.000000, best_reward: -45.000000 ± 15.000000 in #0\n",
      "Epoch #3: 5001it [03:36, 23.08it/s, env_step=15000, len=50, loss/actor=-10.321, loss/critics=3.406, n/ep=1, n/st=1, rew=-50.00]              \n",
      "Epoch #3: test_reward: -50.000000 ± 0.000000, best_reward: -45.000000 ± 15.000000 in #0\n",
      "Epoch #4: 5001it [03:44, 22.30it/s, env_step=20000, len=50, loss/actor=-11.472, loss/critics=3.975, n/ep=1, n/st=1, rew=-50.00]\n",
      "Epoch #4: test_reward: -50.000000 ± 0.000000, best_reward: -45.000000 ± 15.000000 in #0\n",
      "Epoch #5: 5001it [03:47, 21.98it/s, env_step=25000, len=50, loss/actor=-12.505, loss/critics=5.102, n/ep=1, n/st=1, rew=-50.00]              \n",
      "Epoch #5: test_reward: -50.000000 ± 0.000000, best_reward: -45.000000 ± 15.000000 in #0\n",
      "Epoch #6: 5001it [03:52, 21.55it/s, env_step=30000, len=50, loss/actor=-13.466, loss/critics=5.468, n/ep=1, n/st=1, rew=-50.00]              \n",
      "Epoch #6: test_reward: -45.000000 ± 15.000000, best_reward: -45.000000 ± 15.000000 in #0\n",
      "Epoch #7: 5001it [03:55, 21.25it/s, env_step=35000, len=50, loss/actor=-14.407, loss/critics=6.032, n/ep=1, n/st=1, rew=-50.00]              \n",
      "Epoch #7: test_reward: -50.000000 ± 0.000000, best_reward: -45.000000 ± 15.000000 in #0\n",
      "Epoch #8: 5001it [04:01, 20.67it/s, env_step=40000, len=50, loss/actor=-15.225, loss/critics=6.402, n/ep=1, n/st=1, rew=-50.00]              \n",
      "Epoch #8: test_reward: -50.000000 ± 0.000000, best_reward: -45.000000 ± 15.000000 in #0\n",
      "Epoch #9: 5001it [04:13, 19.77it/s, env_step=45000, len=50, loss/actor=-16.002, loss/critics=6.616, n/ep=1, n/st=1, rew=-50.00]              \n",
      "Epoch #9: test_reward: -50.000000 ± 0.000000, best_reward: -45.000000 ± 15.000000 in #0\n",
      "Epoch #10: 5001it [04:13, 19.69it/s, env_step=50000, len=50, loss/actor=-16.616, loss/critics=7.093, n/ep=1, n/st=1, rew=-50.00]              \n",
      "Epoch #10: test_reward: -45.000000 ± 15.000000, best_reward: -45.000000 ± 15.000000 in #0\n",
      "Epoch #11: 5001it [04:18, 19.35it/s, env_step=55000, len=50, loss/actor=-16.976, loss/critics=7.485, n/ep=1, n/st=1, rew=-50.00]              \n",
      "Epoch #11: test_reward: -50.000000 ± 0.000000, best_reward: -45.000000 ± 15.000000 in #0\n",
      "Epoch #12: 5001it [04:18, 19.33it/s, env_step=60000, len=50, loss/actor=-17.236, loss/critics=7.520, n/ep=1, n/st=1, rew=-50.00]              \n",
      "Epoch #12: test_reward: -50.000000 ± 0.000000, best_reward: -45.000000 ± 15.000000 in #0\n",
      "Epoch #13: 5001it [04:21, 19.10it/s, env_step=65000, len=50, loss/actor=-17.173, loss/critics=7.649, n/ep=1, n/st=1, rew=-50.00]              \n",
      "Epoch #13: test_reward: -40.000000 ± 20.000000, best_reward: -40.000000 ± 20.000000 in #13\n",
      "Epoch #14: 5001it [04:23, 18.98it/s, env_step=70000, len=50, loss/actor=-16.794, loss/critics=6.609, n/ep=1, n/st=1, rew=-50.00]              \n",
      "Epoch #14: test_reward: -45.000000 ± 15.000000, best_reward: -40.000000 ± 20.000000 in #13\n",
      "Epoch #15: 5001it [04:25, 18.81it/s, env_step=75000, len=50, loss/actor=-16.356, loss/critics=6.610, n/ep=1, n/st=1, rew=0.00]              \n",
      "Epoch #15: test_reward: -50.000000 ± 0.000000, best_reward: -40.000000 ± 20.000000 in #13\n",
      "Epoch #16: 5001it [04:25, 18.86it/s, env_step=80000, len=50, loss/actor=-16.130, loss/critics=5.965, n/ep=1, n/st=1, rew=-50.00]              \n",
      "Epoch #16: test_reward: -40.000000 ± 20.000000, best_reward: -40.000000 ± 20.000000 in #13\n",
      "Epoch #17: 5001it [04:28, 18.66it/s, env_step=85000, len=50, loss/actor=-15.539, loss/critics=5.815, n/ep=1, n/st=1, rew=-50.00]              \n",
      "Epoch #17: test_reward: -45.000000 ± 15.000000, best_reward: -40.000000 ± 20.000000 in #13\n",
      "Epoch #18: 5001it [04:26, 18.73it/s, env_step=90000, len=50, loss/actor=-15.059, loss/critics=5.284, n/ep=1, n/st=1, rew=-50.00]\n",
      "Epoch #18: test_reward: -50.000000 ± 0.000000, best_reward: -40.000000 ± 20.000000 in #13\n",
      "Epoch #19: 5001it [04:27, 18.70it/s, env_step=95000, len=50, loss/actor=-14.401, loss/critics=4.662, n/ep=1, n/st=1, rew=-50.00]              \n",
      "Epoch #19: test_reward: -50.000000 ± 0.000000, best_reward: -40.000000 ± 20.000000 in #13\n",
      "Epoch #20: 5001it [04:25, 18.81it/s, env_step=100000, len=50, loss/actor=-13.808, loss/critics=4.279, n/ep=1, n/st=1, rew=-50.00]              \n",
      "Epoch #20: test_reward: -50.000000 ± 0.000000, best_reward: -40.000000 ± 20.000000 in #13\n",
      "Epoch #21: 5001it [04:26, 18.80it/s, env_step=105000, len=50, loss/actor=-13.530, loss/critics=3.741, n/ep=1, n/st=1, rew=-50.00]              \n",
      "Epoch #21: test_reward: -45.000000 ± 15.000000, best_reward: -40.000000 ± 20.000000 in #13\n",
      "Epoch #22: 5001it [04:24, 18.94it/s, env_step=110000, len=50, loss/actor=-13.115, loss/critics=3.448, n/ep=1, n/st=1, rew=-50.00]              \n",
      "Epoch #22: test_reward: -45.000000 ± 15.000000, best_reward: -40.000000 ± 20.000000 in #13\n",
      "Epoch #23: 5001it [04:22, 19.02it/s, env_step=115000, len=50, loss/actor=-13.011, loss/critics=3.244, n/ep=1, n/st=1, rew=-50.00]              \n",
      "Epoch #23: test_reward: -45.000000 ± 15.000000, best_reward: -40.000000 ± 20.000000 in #13\n",
      "Epoch #24: 5001it [04:24, 18.94it/s, env_step=120000, len=50, loss/actor=-12.644, loss/critics=2.713, n/ep=1, n/st=1, rew=-50.00]              \n",
      "Epoch #24: test_reward: -50.000000 ± 0.000000, best_reward: -40.000000 ± 20.000000 in #13\n",
      "Epoch #25: 5001it [04:23, 19.00it/s, env_step=125000, len=50, loss/actor=-12.528, loss/critics=2.635, n/ep=1, n/st=1, rew=-50.00]              \n",
      "Epoch #25: test_reward: -45.000000 ± 15.000000, best_reward: -40.000000 ± 20.000000 in #13\n",
      "Epoch #26: 5001it [04:25, 18.85it/s, env_step=130000, len=50, loss/actor=-12.519, loss/critics=2.434, n/ep=1, n/st=1, rew=-50.00]              \n",
      "Epoch #26: test_reward: -50.000000 ± 0.000000, best_reward: -40.000000 ± 20.000000 in #13\n",
      "Epoch #27: 5001it [04:25, 18.80it/s, env_step=135000, len=50, loss/actor=-12.430, loss/critics=2.409, n/ep=1, n/st=1, rew=-50.00]\n",
      "Epoch #27: test_reward: -45.000000 ± 15.000000, best_reward: -40.000000 ± 20.000000 in #13\n",
      "Epoch #28: 5001it [04:25, 18.83it/s, env_step=140000, len=50, loss/actor=-12.538, loss/critics=2.301, n/ep=1, n/st=1, rew=-50.00]              \n",
      "Epoch #28: test_reward: -50.000000 ± 0.000000, best_reward: -40.000000 ± 20.000000 in #13\n",
      "Epoch #29: 5001it [04:24, 18.89it/s, env_step=145000, len=50, loss/actor=-12.633, loss/critics=2.289, n/ep=1, n/st=1, rew=-50.00]              \n",
      "Epoch #29: test_reward: -50.000000 ± 0.000000, best_reward: -40.000000 ± 20.000000 in #13\n",
      "Epoch #30: 5001it [04:24, 18.88it/s, env_step=150000, len=50, loss/actor=-12.806, loss/critics=2.244, n/ep=1, n/st=1, rew=-50.00]              \n",
      "Epoch #30: test_reward: -45.000000 ± 15.000000, best_reward: -40.000000 ± 20.000000 in #13\n",
      "Epoch #31: 5001it [04:26, 18.74it/s, env_step=155000, len=50, loss/actor=-12.770, loss/critics=2.147, n/ep=1, n/st=1, rew=-50.00]              \n",
      "Epoch #31: test_reward: -50.000000 ± 0.000000, best_reward: -40.000000 ± 20.000000 in #13\n",
      "Epoch #32: 5001it [04:25, 18.81it/s, env_step=160000, len=50, loss/actor=-12.721, loss/critics=2.166, n/ep=1, n/st=1, rew=-50.00]              \n",
      "Epoch #32: test_reward: -45.000000 ± 15.000000, best_reward: -40.000000 ± 20.000000 in #13\n",
      "Epoch #33: 5001it [04:26, 18.79it/s, env_step=165000, len=50, loss/actor=-12.893, loss/critics=2.117, n/ep=1, n/st=1, rew=-50.00]              \n",
      "Epoch #33: test_reward: -45.000000 ± 15.000000, best_reward: -40.000000 ± 20.000000 in #13\n",
      "Epoch #34: 5001it [04:26, 18.77it/s, env_step=170000, len=50, loss/actor=-12.801, loss/critics=2.090, n/ep=1, n/st=1, rew=-50.00]\n",
      "Epoch #34: test_reward: -50.000000 ± 0.000000, best_reward: -40.000000 ± 20.000000 in #13\n",
      "Epoch #35: 5001it [04:27, 18.72it/s, env_step=175000, len=50, loss/actor=-12.749, loss/critics=2.042, n/ep=1, n/st=1, rew=-50.00]              \n",
      "Epoch #35: test_reward: -50.000000 ± 0.000000, best_reward: -40.000000 ± 20.000000 in #13\n",
      "Epoch #36: 5001it [04:27, 18.72it/s, env_step=180000, len=50, loss/actor=-12.689, loss/critics=1.900, n/ep=1, n/st=1, rew=-50.00]              \n",
      "Epoch #36: test_reward: -45.000000 ± 15.000000, best_reward: -40.000000 ± 20.000000 in #13\n",
      "Epoch #37: 5001it [04:26, 18.79it/s, env_step=185000, len=50, loss/actor=-12.627, loss/critics=2.004, n/ep=1, n/st=1, rew=0.00]\n",
      "Epoch #37: test_reward: -45.000000 ± 15.000000, best_reward: -40.000000 ± 20.000000 in #13\n",
      "Epoch #38: 5001it [04:26, 18.75it/s, env_step=190000, len=50, loss/actor=-12.536, loss/critics=1.804, n/ep=1, n/st=1, rew=-50.00]              \n",
      "Epoch #38: test_reward: -40.000000 ± 20.000000, best_reward: -40.000000 ± 20.000000 in #13\n",
      "Epoch #39: 5001it [04:25, 18.80it/s, env_step=195000, len=50, loss/actor=-12.509, loss/critics=1.861, n/ep=1, n/st=1, rew=-50.00]              \n",
      "Epoch #39: test_reward: -45.000000 ± 15.000000, best_reward: -40.000000 ± 20.000000 in #13\n",
      "Epoch #40: 5001it [04:25, 18.81it/s, env_step=200000, len=50, loss/actor=-12.428, loss/critics=1.793, n/ep=1, n/st=1, rew=0.00]              \n",
      "Epoch #40: test_reward: -42.000000 ± 16.613248, best_reward: -40.000000 ± 20.000000 in #13\n",
      "Epoch #41: 5001it [04:24, 18.88it/s, env_step=205000, len=50, loss/actor=-12.294, loss/critics=1.962, n/ep=1, n/st=1, rew=-50.00]\n",
      "Epoch #41: test_reward: -50.000000 ± 0.000000, best_reward: -40.000000 ± 20.000000 in #13\n",
      "Epoch #42: 5001it [04:25, 18.81it/s, env_step=210000, len=50, loss/actor=-12.089, loss/critics=1.935, n/ep=1, n/st=1, rew=-50.00]              \n",
      "Epoch #42: test_reward: -50.000000 ± 0.000000, best_reward: -40.000000 ± 20.000000 in #13\n",
      "Epoch #43: 5001it [04:25, 18.84it/s, env_step=215000, len=50, loss/actor=-12.102, loss/critics=1.762, n/ep=1, n/st=1, rew=-50.00]              \n",
      "Epoch #43: test_reward: -50.000000 ± 0.000000, best_reward: -40.000000 ± 20.000000 in #13\n",
      "Epoch #44: 5001it [04:25, 18.83it/s, env_step=220000, len=50, loss/actor=-11.976, loss/critics=1.914, n/ep=1, n/st=1, rew=-50.00]              \n",
      "Epoch #44: test_reward: -45.000000 ± 15.000000, best_reward: -40.000000 ± 20.000000 in #13\n",
      "Epoch #45: 5001it [04:25, 18.81it/s, env_step=225000, len=50, loss/actor=-11.887, loss/critics=2.027, n/ep=1, n/st=1, rew=-50.00]              \n",
      "Epoch #45: test_reward: -45.000000 ± 15.000000, best_reward: -40.000000 ± 20.000000 in #13\n",
      "Epoch #46: 5001it [04:25, 18.81it/s, env_step=230000, len=50, loss/actor=-11.825, loss/critics=1.953, n/ep=1, n/st=1, rew=-50.00]              \n",
      "Epoch #46: test_reward: -45.000000 ± 15.000000, best_reward: -40.000000 ± 20.000000 in #13\n",
      "Epoch #47: 5001it [04:25, 18.86it/s, env_step=235000, len=50, loss/actor=-11.785, loss/critics=1.992, n/ep=1, n/st=1, rew=-50.00]\n",
      "Epoch #47: test_reward: -50.000000 ± 0.000000, best_reward: -40.000000 ± 20.000000 in #13\n",
      "Epoch #48: 5001it [04:25, 18.81it/s, env_step=240000, len=50, loss/actor=-11.913, loss/critics=1.994, n/ep=1, n/st=1, rew=-50.00]              \n",
      "Epoch #48: test_reward: -50.000000 ± 0.000000, best_reward: -40.000000 ± 20.000000 in #13\n",
      "Epoch #49: 5001it [04:25, 18.83it/s, env_step=245000, len=50, loss/actor=-11.772, loss/critics=1.941, n/ep=1, n/st=1, rew=-50.00]              \n",
      "Epoch #49: test_reward: -50.000000 ± 0.000000, best_reward: -40.000000 ± 20.000000 in #13\n",
      "Epoch #50: 5001it [04:26, 18.76it/s, env_step=250000, len=50, loss/actor=-11.895, loss/critics=1.938, n/ep=1, n/st=1, rew=-50.00]\n",
      "Epoch #50: test_reward: -40.000000 ± 20.000000, best_reward: -40.000000 ± 20.000000 in #13\n",
      "Epoch #51: 5001it [04:26, 18.78it/s, env_step=255000, len=50, loss/actor=-11.812, loss/critics=1.982, n/ep=1, n/st=1, rew=-24.00]\n",
      "Epoch #51: test_reward: -45.000000 ± 15.000000, best_reward: -40.000000 ± 20.000000 in #13\n",
      "Epoch #52: 5001it [04:27, 18.68it/s, env_step=260000, len=50, loss/actor=-11.846, loss/critics=2.046, n/ep=1, n/st=1, rew=0.00]              \n",
      "Epoch #52: test_reward: -49.200000 ± 2.400000, best_reward: -40.000000 ± 20.000000 in #13\n",
      "Epoch #53: 5001it [04:27, 18.71it/s, env_step=265000, len=50, loss/actor=-11.731, loss/critics=1.959, n/ep=1, n/st=1, rew=0.00]              \n",
      "Epoch #53: test_reward: -35.400000 ± 22.325770, best_reward: -35.400000 ± 22.325770 in #53\n",
      "Epoch #54: 5001it [04:26, 18.78it/s, env_step=270000, len=50, loss/actor=-11.842, loss/critics=2.278, n/ep=1, n/st=1, rew=-50.00]              \n",
      "Epoch #54: test_reward: -45.000000 ± 15.000000, best_reward: -35.400000 ± 22.325770 in #53\n",
      "Epoch #55: 5001it [04:26, 18.75it/s, env_step=275000, len=50, loss/actor=-11.661, loss/critics=2.060, n/ep=1, n/st=1, rew=-50.00]              \n",
      "Epoch #55: test_reward: -45.000000 ± 15.000000, best_reward: -35.400000 ± 22.325770 in #53\n",
      "Epoch #56: 5001it [04:26, 18.77it/s, env_step=280000, len=50, loss/actor=-11.577, loss/critics=2.023, n/ep=1, n/st=1, rew=-50.00]              \n",
      "Epoch #56: test_reward: -45.000000 ± 15.000000, best_reward: -35.400000 ± 22.325770 in #53\n",
      "Epoch #57: 5001it [04:26, 18.75it/s, env_step=285000, len=50, loss/actor=-11.488, loss/critics=1.897, n/ep=1, n/st=1, rew=-50.00]\n",
      "Epoch #57: test_reward: -45.000000 ± 15.000000, best_reward: -35.400000 ± 22.325770 in #53\n",
      "Epoch #58: 5001it [04:26, 18.74it/s, env_step=290000, len=50, loss/actor=-11.346, loss/critics=1.918, n/ep=1, n/st=1, rew=-50.00]              \n",
      "Epoch #58: test_reward: -45.000000 ± 15.000000, best_reward: -35.400000 ± 22.325770 in #53\n",
      "Epoch #59: 5001it [04:26, 18.73it/s, env_step=295000, len=50, loss/actor=-11.319, loss/critics=2.183, n/ep=1, n/st=1, rew=-50.00]              \n",
      "Epoch #59: test_reward: -50.000000 ± 0.000000, best_reward: -35.400000 ± 22.325770 in #53\n",
      "Epoch #60: 5001it [04:25, 18.82it/s, env_step=300000, len=50, loss/actor=-11.243, loss/critics=2.040, n/ep=1, n/st=1, rew=-50.00]              \n",
      "Epoch #60: test_reward: -45.000000 ± 15.000000, best_reward: -35.400000 ± 22.325770 in #53\n",
      "Epoch #61: 5001it [04:22, 19.05it/s, env_step=305000, len=50, loss/actor=-11.254, loss/critics=2.033, n/ep=1, n/st=1, rew=-50.00]              \n",
      "Epoch #61: test_reward: -45.000000 ± 15.000000, best_reward: -35.400000 ± 22.325770 in #53\n",
      "Epoch #62: 5001it [04:21, 19.09it/s, env_step=310000, len=50, loss/actor=-11.010, loss/critics=1.939, n/ep=1, n/st=1, rew=-50.00]              \n",
      "Epoch #62: test_reward: -50.000000 ± 0.000000, best_reward: -35.400000 ± 22.325770 in #53\n",
      "Epoch #63: 5001it [04:22, 19.04it/s, env_step=315000, len=50, loss/actor=-10.888, loss/critics=2.042, n/ep=1, n/st=1, rew=0.00]              \n",
      "Epoch #63: test_reward: -40.000000 ± 20.000000, best_reward: -35.400000 ± 22.325770 in #53\n",
      "Epoch #64: 5001it [04:22, 19.07it/s, env_step=320000, len=50, loss/actor=-10.757, loss/critics=2.062, n/ep=1, n/st=1, rew=-50.00]              \n",
      "Epoch #64: test_reward: -40.000000 ± 20.000000, best_reward: -35.400000 ± 22.325770 in #53\n",
      "Epoch #65: 5001it [04:21, 19.13it/s, env_step=325000, len=50, loss/actor=-10.887, loss/critics=1.947, n/ep=1, n/st=1, rew=-50.00]              \n",
      "Epoch #65: test_reward: -50.000000 ± 0.000000, best_reward: -35.400000 ± 22.325770 in #53\n",
      "Epoch #66: 5001it [04:20, 19.18it/s, env_step=330000, len=50, loss/actor=-10.744, loss/critics=1.963, n/ep=1, n/st=1, rew=-50.00]              \n",
      "Epoch #66: test_reward: -50.000000 ± 0.000000, best_reward: -35.400000 ± 22.325770 in #53\n",
      "Epoch #67: 5001it [04:20, 19.18it/s, env_step=335000, len=50, loss/actor=-10.605, loss/critics=1.898, n/ep=1, n/st=1, rew=-50.00]\n",
      "Epoch #67: test_reward: -50.000000 ± 0.000000, best_reward: -35.400000 ± 22.325770 in #53\n",
      "Epoch #68: 5001it [04:25, 18.83it/s, env_step=340000, len=50, loss/actor=-10.544, loss/critics=1.816, n/ep=1, n/st=1, rew=-50.00]\n",
      "Epoch #68: test_reward: -50.000000 ± 0.000000, best_reward: -35.400000 ± 22.325770 in #53\n",
      "Epoch #69: 5001it [04:31, 18.42it/s, env_step=345000, len=50, loss/actor=-10.667, loss/critics=1.807, n/ep=1, n/st=1, rew=-50.00]              \n",
      "Epoch #69: test_reward: -45.000000 ± 15.000000, best_reward: -35.400000 ± 22.325770 in #53\n",
      "Epoch #70: 5001it [04:24, 18.89it/s, env_step=350000, len=50, loss/actor=-10.685, loss/critics=1.946, n/ep=1, n/st=1, rew=-50.00]\n",
      "Epoch #70: test_reward: -50.000000 ± 0.000000, best_reward: -35.400000 ± 22.325770 in #53\n",
      "Epoch #71: 5001it [04:47, 17.38it/s, env_step=355000, len=50, loss/actor=-10.532, loss/critics=2.004, n/ep=1, n/st=1, rew=-50.00]              \n",
      "Epoch #71: test_reward: -50.000000 ± 0.000000, best_reward: -35.400000 ± 22.325770 in #53\n",
      "Epoch #72: 5001it [04:12, 19.84it/s, env_step=360000, len=50, loss/actor=-10.535, loss/critics=2.064, n/ep=1, n/st=1, rew=-50.00]\n",
      "Epoch #72: test_reward: -50.000000 ± 0.000000, best_reward: -35.400000 ± 22.325770 in #53\n",
      "Epoch #73: 5001it [04:12, 19.82it/s, env_step=365000, len=50, loss/actor=-10.495, loss/critics=1.917, n/ep=1, n/st=1, rew=-50.00]              \n",
      "Epoch #73: test_reward: -45.000000 ± 15.000000, best_reward: -35.400000 ± 22.325770 in #53\n",
      "Epoch #74: 5001it [04:10, 19.97it/s, env_step=370000, len=50, loss/actor=-10.623, loss/critics=2.107, n/ep=1, n/st=1, rew=-50.00]              \n",
      "Epoch #74: test_reward: -40.000000 ± 20.000000, best_reward: -35.400000 ± 22.325770 in #53\n",
      "Epoch #75: 5001it [04:10, 19.99it/s, env_step=375000, len=50, loss/actor=-10.783, loss/critics=2.181, n/ep=1, n/st=1, rew=-50.00]\n",
      "Epoch #75: test_reward: -50.000000 ± 0.000000, best_reward: -35.400000 ± 22.325770 in #53\n",
      "Epoch #76: 5001it [04:14, 19.63it/s, env_step=380000, len=50, loss/actor=-10.819, loss/critics=2.345, n/ep=1, n/st=1, rew=-50.00]              \n",
      "Epoch #76: test_reward: -40.700000 ± 17.435883, best_reward: -35.400000 ± 22.325770 in #53\n",
      "Epoch #77: 5001it [04:12, 19.84it/s, env_step=385000, len=50, loss/actor=-10.661, loss/critics=2.300, n/ep=1, n/st=1, rew=-50.00]              \n",
      "Epoch #77: test_reward: -36.100000 ± 21.421718, best_reward: -35.400000 ± 22.325770 in #53\n",
      "Epoch #78: 5001it [04:14, 19.69it/s, env_step=390000, len=50, loss/actor=-10.450, loss/critics=2.225, n/ep=1, n/st=1, rew=-50.00]              \n",
      "Epoch #78: test_reward: -37.600000 ± 19.617339, best_reward: -35.400000 ± 22.325770 in #53\n",
      "Epoch #79: 5001it [04:11, 19.87it/s, env_step=395000, len=50, loss/actor=-10.261, loss/critics=2.410, n/ep=1, n/st=1, rew=-50.00]              \n",
      "Epoch #79: test_reward: -50.000000 ± 0.000000, best_reward: -35.400000 ± 22.325770 in #53\n",
      "Epoch #80: 5001it [04:23, 18.97it/s, env_step=400000, len=50, loss/actor=-10.060, loss/critics=2.311, n/ep=1, n/st=1, rew=-50.00]              \n",
      "Epoch #80: test_reward: -50.000000 ± 0.000000, best_reward: -35.400000 ± 22.325770 in #53\n",
      "Epoch #81: 5001it [04:10, 20.00it/s, env_step=405000, len=50, loss/actor=-9.817, loss/critics=2.426, n/ep=1, n/st=1, rew=-50.00]              \n",
      "Epoch #81: test_reward: -44.300000 ± 14.913417, best_reward: -35.400000 ± 22.325770 in #53\n",
      "Epoch #82: 5001it [04:09, 20.08it/s, env_step=410000, len=50, loss/actor=-9.661, loss/critics=2.576, n/ep=1, n/st=1, rew=-50.00]\n",
      "Epoch #82: test_reward: -50.000000 ± 0.000000, best_reward: -35.400000 ± 22.325770 in #53\n",
      "Epoch #83: 5001it [04:08, 20.15it/s, env_step=415000, len=50, loss/actor=-9.478, loss/critics=2.464, n/ep=1, n/st=1, rew=-50.00]              \n",
      "Epoch #83: test_reward: -49.800000 ± 0.600000, best_reward: -35.400000 ± 22.325770 in #53\n",
      "Epoch #84: 5001it [04:14, 19.62it/s, env_step=420000, len=50, loss/actor=-9.184, loss/critics=2.529, n/ep=1, n/st=1, rew=-25.00]\n",
      "Epoch #84: test_reward: -50.000000 ± 0.000000, best_reward: -35.400000 ± 22.325770 in #53\n",
      "Epoch #85: 5001it [04:26, 18.74it/s, env_step=425000, len=50, loss/actor=-8.872, loss/critics=2.560, n/ep=1, n/st=1, rew=-50.00]              \n",
      "Epoch #85: test_reward: -45.000000 ± 15.000000, best_reward: -35.400000 ± 22.325770 in #53\n",
      "Epoch #86: 5001it [04:17, 19.38it/s, env_step=430000, len=50, loss/actor=-8.661, loss/critics=2.499, n/ep=1, n/st=1, rew=-50.00]              \n",
      "Epoch #86: test_reward: -50.000000 ± 0.000000, best_reward: -35.400000 ± 22.325770 in #53\n",
      "Epoch #87: 5001it [04:28, 18.64it/s, env_step=435000, len=50, loss/actor=-8.401, loss/critics=2.507, n/ep=1, n/st=1, rew=-50.00]              \n",
      "Epoch #87: test_reward: -37.400000 ± 19.622436, best_reward: -35.400000 ± 22.325770 in #53\n",
      "Epoch #88: 5001it [04:25, 18.83it/s, env_step=440000, len=50, loss/actor=-7.943, loss/critics=2.422, n/ep=1, n/st=1, rew=-39.00]\n",
      "Epoch #88: test_reward: -41.100000 ± 17.969140, best_reward: -35.400000 ± 22.325770 in #53\n",
      "Epoch #89: 5001it [04:24, 18.89it/s, env_step=445000, len=50, loss/actor=-7.718, loss/critics=2.404, n/ep=1, n/st=1, rew=-50.00]              \n",
      "Epoch #89: test_reward: -44.400000 ± 11.629273, best_reward: -35.400000 ± 22.325770 in #53\n",
      "Epoch #90: 5001it [04:23, 18.96it/s, env_step=450000, len=50, loss/actor=-7.363, loss/critics=2.277, n/ep=1, n/st=1, rew=-50.00]              \n",
      "Epoch #90: test_reward: -39.400000 ± 16.044937, best_reward: -35.400000 ± 22.325770 in #53\n",
      "Epoch #91: 5001it [04:22, 19.03it/s, env_step=455000, len=50, loss/actor=-7.054, loss/critics=2.437, n/ep=1, n/st=1, rew=-50.00]              \n",
      "Epoch #91: test_reward: -38.300000 ± 17.877640, best_reward: -35.400000 ± 22.325770 in #53\n",
      "Epoch #92: 5001it [04:21, 19.14it/s, env_step=460000, len=50, loss/actor=-6.800, loss/critics=2.528, n/ep=1, n/st=1, rew=-50.00]              \n",
      "Epoch #92: test_reward: -41.200000 ± 15.190787, best_reward: -35.400000 ± 22.325770 in #53\n",
      "Epoch #93: 5001it [04:15, 19.60it/s, env_step=465000, len=50, loss/actor=-6.586, loss/critics=2.515, n/ep=1, n/st=1, rew=-50.00]              \n",
      "Epoch #93: test_reward: -31.100000 ± 19.511279, best_reward: -31.100000 ± 19.511279 in #93\n",
      "Epoch #94: 5001it [04:20, 19.18it/s, env_step=470000, len=50, loss/actor=-6.332, loss/critics=2.508, n/ep=1, n/st=1, rew=-50.00]              \n",
      "Epoch #94: test_reward: -22.700000 ± 18.028034, best_reward: -22.700000 ± 18.028034 in #94\n",
      "Epoch #95: 5001it [04:19, 19.29it/s, env_step=475000, len=50, loss/actor=-6.194, loss/critics=2.654, n/ep=1, n/st=1, rew=-50.00]              \n",
      "Epoch #95: test_reward: -40.600000 ± 17.596591, best_reward: -22.700000 ± 18.028034 in #94\n",
      "Epoch #96: 5001it [04:18, 19.36it/s, env_step=480000, len=50, loss/actor=-6.063, loss/critics=2.678, n/ep=1, n/st=1, rew=-23.00]              \n",
      "Epoch #96: test_reward: -37.500000 ± 16.390546, best_reward: -22.700000 ± 18.028034 in #94\n",
      "Epoch #97: 5001it [04:21, 19.11it/s, env_step=485000, len=50, loss/actor=-5.853, loss/critics=2.670, n/ep=1, n/st=1, rew=-13.00]              \n",
      "Epoch #97: test_reward: -30.900000 ± 21.833232, best_reward: -22.700000 ± 18.028034 in #94\n",
      "Epoch #98: 5001it [04:19, 19.25it/s, env_step=490000, len=50, loss/actor=-5.635, loss/critics=2.689, n/ep=1, n/st=1, rew=-50.00]              \n",
      "Epoch #98: test_reward: -20.600000 ± 19.805050, best_reward: -20.600000 ± 19.805050 in #98\n",
      "Epoch #99: 5001it [04:18, 19.36it/s, env_step=495000, len=50, loss/actor=-5.434, loss/critics=2.694, n/ep=1, n/st=1, rew=-38.00]              \n",
      "Epoch #99: test_reward: -25.700000 ± 17.430146, best_reward: -20.600000 ± 19.805050 in #98\n",
      "Epoch #100: 5001it [04:15, 19.54it/s, env_step=500000, len=50, loss/actor=-5.415, loss/critics=2.551, n/ep=1, n/st=1, rew=-29.00]              \n",
      "Epoch #100: test_reward: -19.200000 ± 13.444702, best_reward: -19.200000 ± 13.444702 in #100\n",
      "{'best_result': '-19.20 ± 13.44',\n",
      " 'best_reward': -19.2,\n",
      " 'duration': '26002.10s',\n",
      " 'test_episode': 1010,\n",
      " 'test_speed': '1156.74 step/s',\n",
      " 'test_step': 50500,\n",
      " 'test_time': '43.66s',\n",
      " 'train_episode': 10000,\n",
      " 'train_speed': '19.26 step/s',\n",
      " 'train_step': 500000,\n",
      " 'train_time/collector': '5211.67s',\n",
      " 'train_time/model': '20746.78s'}\n",
      "Final reward: -19.3, length: 50.0\n"
     ]
    }
   ],
   "source": [
    "!python fetch_her_redq.py --task FetchPush-v2 \\\n",
    "      --hidden-sizes 256 256 256 --actor-lr 1e-4 --critic-lr 1e-4 \\\n",
    "      --gamma 0.98 --epoch 100 --her-horizon 50"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
